{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2f48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Fix path setup ---\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)  # <-- add the ROOT, not the src folder directly!\n",
    "\n",
    "from src.model_definitions import make_resnet18\n",
    "from src.video_model_definition import create_mvit_model\n",
    "\n",
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6a0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 30 output classes for ResNet18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Step 2: Load FP32 models ===\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Base paths\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"models\", \"model_final\")\n",
    "QUANT_DIR = os.path.join(PROJECT_ROOT, \"models\", \"model_quantized\")\n",
    "os.makedirs(QUANT_DIR, exist_ok=True)\n",
    "\n",
    "# ----- Load ResNet18 dynamically -----\n",
    "resnet_path = os.path.join(MODEL_DIR, \"resnet_asl_final.pth\")\n",
    "state = torch.load(resnet_path, map_location=\"cpu\")\n",
    "\n",
    "# Determine class count automatically from fc layer in checkpoint\n",
    "if \"fc.weight\" in state:\n",
    "    num_classes = state[\"fc.weight\"].shape[0]\n",
    "else:\n",
    "    # fallback if checkpoint is wrapped (e.g. from DataParallel or a dict)\n",
    "    for k, v in state.items():\n",
    "        if \"fc.weight\" in k:\n",
    "            num_classes = v.shape[0]\n",
    "            break\n",
    "\n",
    "print(f\"Detected {num_classes} output classes for ResNet18\")\n",
    "\n",
    "# Now build model with correct classifier size\n",
    "resnet = make_resnet18(num_classes=num_classes, pretrained=False)\n",
    "resnet.load_state_dict(state, strict=True)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f8940d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1990 output classes for MViT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MViT(\n",
       "  (conv_proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))\n",
       "  (pos_encoding): PositionalEncoding()\n",
       "  (blocks): ModuleList(\n",
       "    (0): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "    )\n",
       "    (1): MultiscaleBlock(\n",
       "      (pool_skip): Pool(\n",
       "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.013333333333333334, mode=row)\n",
       "      (project): Linear(in_features=96, out_features=192, bias=True)\n",
       "    )\n",
       "    (2): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.02666666666666667, mode=row)\n",
       "    )\n",
       "    (3): MultiscaleBlock(\n",
       "      (pool_skip): Pool(\n",
       "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.04000000000000001, mode=row)\n",
       "      (project): Linear(in_features=192, out_features=384, bias=True)\n",
       "    )\n",
       "    (4): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.05333333333333334, mode=row)\n",
       "    )\n",
       "    (5): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
       "    )\n",
       "    (6): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.08000000000000002, mode=row)\n",
       "    )\n",
       "    (7): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.09333333333333334, mode=row)\n",
       "    )\n",
       "    (8): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.10666666666666667, mode=row)\n",
       "    )\n",
       "    (9): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
       "    )\n",
       "    (10): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
       "    )\n",
       "    (11): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.14666666666666667, mode=row)\n",
       "    )\n",
       "    (12): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.16000000000000003, mode=row)\n",
       "    )\n",
       "    (13): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.17333333333333334, mode=row)\n",
       "    )\n",
       "    (14): MultiscaleBlock(\n",
       "      (pool_skip): Pool(\n",
       "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.18666666666666668, mode=row)\n",
       "      (project): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "    (15): MultiscaleBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiscaleAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (pool_q): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_k): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (pool_v): Pool(\n",
       "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
       "          (norm_act): Sequential(\n",
       "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=True)\n",
       "    (1): Linear(in_features=768, out_features=1990, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- Load MViT dynamically -----\n",
    "mvit_path = os.path.join(MODEL_DIR, \"mvit_wlasl_final.pth\")\n",
    "mvit_state = torch.load(mvit_path, map_location=\"cpu\")\n",
    "\n",
    "if \"head.1.weight\" in mvit_state:\n",
    "    mvit_classes = mvit_state[\"head.1.weight\"].shape[0]\n",
    "else:\n",
    "    for k, v in mvit_state.items():\n",
    "        if \"head.1.weight\" in k:\n",
    "            mvit_classes = v.shape[0]\n",
    "            break\n",
    "\n",
    "print(f\"Detected {mvit_classes} output classes for MViT\")\n",
    "\n",
    "mvit = create_mvit_model(num_classes=mvit_classes, pretrained=False)\n",
    "mvit.load_state_dict(mvit_state, strict=True)\n",
    "mvit.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac79b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7529/1208047456.py:23: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  resnet_quant = quantize_dynamic(resnet, {torch.nn.Linear}, dtype=torch.qint8)\n",
      "/tmp/ipykernel_7529/1208047456.py:24: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  mvit_quant   = quantize_dynamic(mvit, {torch.nn.Linear}, dtype=torch.qint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models quantized in PyTorch (dynamic INT8 for Linear layers).\n"
     ]
    }
   ],
   "source": [
    "# === Step 3.1: Setup paths and dummy inputs ===\n",
    "import torch\n",
    "import os\n",
    "from torch.ao.quantization import quantize_dynamic  # modern API\n",
    "from onnxruntime.quantization import QuantType\n",
    "\n",
    "# 📂 Folder paths\n",
    "MODEL_FINAL = os.path.join(PROJECT_ROOT, \"models\", \"model_final\")\n",
    "MODEL_INTER = os.path.join(PROJECT_ROOT, \"models\", \"model_inter\")\n",
    "MODEL_QUANT = os.path.join(PROJECT_ROOT, \"models\", \"model_quantized\")\n",
    "\n",
    "os.makedirs(MODEL_INTER, exist_ok=True)\n",
    "os.makedirs(MODEL_QUANT, exist_ok=True)\n",
    "\n",
    "# 🧩 Dummy inputs for tracing\n",
    "dummy_resnet = torch.randn(1, 3, 224, 224)\n",
    "dummy_mvit   = torch.randn(1, 3, 16, 224, 224)\n",
    "\n",
    "# === Step 3.2: Quantize models inside PyTorch (weights-only) ===\n",
    "from torch.ao.quantization import quantize_dynamic\n",
    "\n",
    "# Quantize both models (only Linear layers to avoid conv/bn issues)\n",
    "resnet_quant = quantize_dynamic(resnet, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "mvit_quant   = quantize_dynamic(mvit, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "print(\"✅ Models quantized in PyTorch (dynamic INT8 for Linear layers).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "880a4894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 16:15:51.945000 7529 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n",
      "Failed to convert the model to the target version 17 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n",
      "W1028 16:15:52.792000 7529 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "[torch.onnx] Obtain model graph for `MViT([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MViT([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert the model to the target version 17 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/genesis/sem1_project/sign-to-speech-with-temporal-correction/env/lib/python3.12/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $18 for Split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 98 of general pattern rewrite rules.\n",
      "✅ Exported FP32 reference ONNX models.\n"
     ]
    }
   ],
   "source": [
    "# === Step 3.3: Export FP32 ONNX models (intermediate) ===\n",
    "resnet_inter_path = os.path.join(MODEL_INTER, \"resnet_asl_fp32.onnx\")\n",
    "mvit_inter_path   = os.path.join(MODEL_INTER, \"mvit_wlasl_fp32.onnx\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    resnet, dummy_resnet, resnet_inter_path,\n",
    "    input_names=[\"input\"], output_names=[\"output\"],\n",
    "    opset_version=17, do_constant_folding=True\n",
    ")\n",
    "torch.onnx.export(\n",
    "    mvit, dummy_mvit, mvit_inter_path,\n",
    "    input_names=[\"input\"], output_names=[\"output\"],\n",
    "    opset_version=17, do_constant_folding=True\n",
    ")\n",
    "\n",
    "print(\"✅ Exported FP32 reference ONNX models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9883607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added to sys.path: /home/genesis/sem1_project/sign-to-speech-with-temporal-correction/src\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add project root to Python path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "print(\"✅ Added to sys.path:\", SRC_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b5a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "['CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(ort.get_device())\n",
    "\n",
    "sess = ort.InferenceSession(\"../models/model_inter/resnet_asl_fp32.onnx\")\n",
    "print(sess.get_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GPU\n",
      "Available providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(\"Device:\", ort.get_device())\n",
    "print(\"Available providers:\", ort.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fadcc08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using GPU acceleration\n",
      "*************** EP Error ***************\n",
      "EP Error /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:123 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:116 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, common::Status> = void] CUDA failure 100: no CUDA-capable device is detected ; GPU=-1 ; hostname=genesis-mkiii ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=280 ; expr=cudaSetDevice(info_.device_id); \n",
      "\n",
      " when using ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "✅ Ran ONNX model on CPUExecutionProvider in 0.011s\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Try to load CUDA provider if available\n",
    "available = ort.get_available_providers()\n",
    "preferred_providers = []\n",
    "\n",
    "if 'CUDAExecutionProvider' in available:\n",
    "    preferred_providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "    print(\"✅ Using GPU acceleration\")\n",
    "else:\n",
    "    preferred_providers = ['CPUExecutionProvider']\n",
    "    print(\"⚠️ GPU not available, running on CPU\")\n",
    "\n",
    "# Create inference session\n",
    "sess = ort.InferenceSession(\n",
    "    \"../models/model_inter/resnet_asl_fp32.onnx\",\n",
    "    providers=preferred_providers\n",
    ")\n",
    "\n",
    "# Test inference\n",
    "inp = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "start = time.time()\n",
    "out = sess.run(None, {sess.get_inputs()[0].name: inp})\n",
    "print(f\"✅ Ran ONNX model on {sess.get_providers()[0]} in {time.time() - start:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e51570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** EP Error ***************\n",
      "EP Error /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:123 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:116 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, common::Status> = void] CUDA failure 100: no CUDA-capable device is detected ; GPU=-1 ; hostname=genesis-mkiii ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=280 ; expr=cudaSetDevice(info_.device_id); \n",
      "\n",
      " when using ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "✅ Ran ONNX model on CPUExecutionProvider in 0.016s\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np, time\n",
    "\n",
    "sess = ort.InferenceSession(\n",
    "    \"../models/model_inter/resnet_asl_fp32.onnx\",\n",
    "    providers=['CUDAExecutionProvider','CPUExecutionProvider']\n",
    ")\n",
    "\n",
    "inp = np.random.randn(1,3,224,224).astype(np.float32)\n",
    "start = time.time()\n",
    "out = sess.run(None, {sess.get_inputs()[0].name: inp})\n",
    "print(f\"✅ Ran ONNX model on {sess.get_providers()[0]} in {time.time()-start:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7bbc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'ResNet', 'label': 'ASL_27', 'confidence': 0.9984676241874695}\n"
     ]
    }
   ],
   "source": [
    "from ensemble_runtime import run_dual_inference\n",
    "import numpy as np\n",
    "\n",
    "# Dummy example until you connect webcam\n",
    "image = np.random.rand(1, 3, 224, 224).astype(np.float32)\n",
    "clip  = np.random.rand(1, 3, 16, 224, 224).astype(np.float32)\n",
    "\n",
    "# Dummy label lists\n",
    "resnet_labels = [f\"ASL_{i}\" for i in range(30)]\n",
    "mvit_labels   = [f\"WLASL_{i}\" for i in range(1990)]\n",
    "\n",
    "result = run_dual_inference(image, clip, resnet_labels, mvit_labels, threshold=0.7)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
