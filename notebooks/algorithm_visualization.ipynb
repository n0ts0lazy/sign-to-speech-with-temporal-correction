{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9151118",
   "metadata": {},
   "source": [
    "# Algorithm Visualization and Performance Analysis\n",
    "\n",
    "This notebook loads trained sign language recognition models, evaluates their performance on the validation dataset, \n",
    "and visualizes metrics such as accuracy, loss, and class-wise confusion matrices.\n",
    "\n",
    "It also serves as the visualization and interpretability module for **Phase 1** of the Sign-to-Speech project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6efa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from src.model import create_model\n",
    "from src.dataset_loader import get_dataloaders  # to be defined in dataset_loader.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and parameters\n",
    "CHECKPOINT_PATH = \"models/checkpoints\"  # change if needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(\"Available checkpoints:\")\n",
    "for f in os.listdir(CHECKPOINT_PATH):\n",
    "    if f.endswith(\".pt\"):\n",
    "        print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data loaders (assuming your dataset_loader.py defines this)\n",
    "train_loader, val_loader, class_names = get_dataloaders(batch_size=32)\n",
    "\n",
    "print(f\"Classes ({len(class_names)}): {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select checkpoint (change filename to whichever version you want)\n",
    "model_path = os.path.join(CHECKPOINT_PATH, \"version_20251012_16_30_00.pt\")\n",
    "\n",
    "model = create_model(num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(f\"✅ Loaded model: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457790d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "correct, total = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b638397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Visualization\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Visualization\n",
    "\n",
    "def imshow(img, title=\"\"):\n",
    "    img = img / 2 + 0.5  # unnormalize if normalized\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "outputs = model(images)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Display first 8 predictions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for idx in range(8):\n",
    "    plt.subplot(2, 4, idx+1)\n",
    "    imshow(images[idx].cpu(), title=f\"T: {class_names[labels[idx]]}\\nP: {class_names[preds[idx]]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Performance Metrics\n",
    "\n",
    "LOG_PATH = \"models/logs/training_log.csv\"  # update path if you save logs\n",
    "if os.path.exists(LOG_PATH):\n",
    "    df = pd.read_csv(LOG_PATH)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(df[\"epoch\"], df[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(df[\"epoch\"], df[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training log found — skip curve visualization.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a91e7e",
   "metadata": {},
   "source": [
    "## Summary of Evaluation\n",
    "\n",
    "- Loaded the trained model checkpoint\n",
    "- Evaluated accuracy and generated classification report\n",
    "- Visualized confusion matrix and sample predictions\n",
    "- (Optional) Displayed training curves from logs\n",
    "\n",
    "Next step: integrate real-time temporal correction visualization once the Phase 2 module is ready.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
